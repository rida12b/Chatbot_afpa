Chatbot RAG AFPA ğŸ¤–
1. Description
Ce projet est un chatbot intelligent basÃ© sur une architecture RAG (Retrieval-Augmented Generation). Il est conÃ§u pour analyser et rÃ©pondre aux questions des utilisateurs en se basant sur une base de connaissances constituÃ©e de documents internes de l'AFPA (PDF, DOCX, PPTX, etc.).
L'application utilise une base de donnÃ©es vectorielle unifiÃ©e pour associer directement le contenu des documents Ã  leurs mÃ©tadonnÃ©es (titre, URL, catÃ©gorie), garantissant des rÃ©ponses rapides et des sources fiables.
2. FonctionnalitÃ©s Principales
ğŸ“„ Ingestion Multi-Format : Prise en charge de divers types de fichiers, y compris PDF, DOCX, PPTX, et images (via OCR).
ğŸ§  Base Vectorielle UnifiÃ©e : Un seul index FAISS contenant les embeddings des documents et leurs mÃ©tadonnÃ©es associÃ©es, y compris les URLs, pour une performance et une cohÃ©rence maximales.
ğŸ” Recherche SÃ©mantique : Utilisation de modÃ¨les de type Sentence-BERT et d'un index FAISS pour trouver les extraits de documents les plus pertinents sÃ©mantiquement.
ğŸ¤– GÃ©nÃ©ration de RÃ©ponses avec Azure OpenAI : Exploitation de la puissance des modÃ¨les de langage d'Azure OpenAI pour synthÃ©tiser des rÃ©ponses claires Ã  partir des documents trouvÃ©s.
ğŸ” Authentification Utilisateur : SystÃ¨me de connexion sÃ©curisÃ© avec gestion des rÃ´les (Utilisateur, Administrateur).
ğŸŒ Interface Web Intuitive : Une interface utilisateur moderne et rÃ©active construite avec Flask, proposant des suggestions de questions et un affichage clair des rÃ©ponses et de leurs sources.
ğŸ³ DÃ©ploiement SimplifiÃ© avec Docker : Scripts de dÃ©ploiement pour Windows (PowerShell) et Linux/macOS pour une mise en service rapide et facile.
3. Architecture du SystÃ¨me
L'architecture actuelle a Ã©tÃ© simplifiÃ©e pour amÃ©liorer la performance et la maintenabilitÃ©.
Phase d'Indexation (Offline) :
Le script create_unified_vectordb.py orchestre le processus :
Les documents du dossier data/documents sont analysÃ©s et leur texte est extrait (ingestion.py).
Le texte est dÃ©coupÃ© en "chunks" (morceaux).
Les mÃ©tadonnÃ©es (y compris les URLs de Url_nom_FINA.json) sont associÃ©es Ã  chaque chunk.
Les chunks sont transformÃ©s en vecteurs (embeddings) via un modÃ¨le Sentence-Transformer.
Un index FAISS (unified_index.bin), un fichier de chunks (unified_chunks.json) et un fichier de mÃ©tadonnÃ©es (unified_metadata.pkl) sont crÃ©Ã©s et sauvegardÃ©s dans le dossier models/.
Phase d'Interrogation (Online) :
L'application app_unified.py est lancÃ©e.
Un utilisateur pose une question via l'interface web.
La question est transformÃ©e en vecteur.
L'index FAISS est interrogÃ© pour trouver les chunks les plus similaires.
Les chunks pertinents, avec leurs mÃ©tadonnÃ©es, sont utilisÃ©s comme contexte pour une requÃªte Ã  l'API Azure OpenAI.
Le modÃ¨le de langage gÃ©nÃ¨re une rÃ©ponse structurÃ©e qui est ensuite affichÃ©e Ã  l'utilisateur.
4. Structure du Projet
Generated code
repomix-output/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/         # (Ã€ crÃ©er) Placer les documents sources ici.
â”‚   â”œâ”€â”€ processed/         # Textes extraits par ingestion.py.
â”‚   â””â”€â”€ url/               # Fichiers JSON de mapping d'URLs.
â”‚
â”œâ”€â”€ models/                # Contient la base de donnÃ©es vectorielle unifiÃ©e.
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ templates/         # Fichiers HTML pour l'interface.
â”‚   â”œâ”€â”€ app_unified.py     # âœ… Application principale (Flask).
â”‚   â”œâ”€â”€ create_unified_vectordb.py # âœ… Script pour crÃ©er la base vectorielle.
â”‚   â”œâ”€â”€ ingestion.py       # Logique d'extraction de texte des fichiers.
â”‚   â”œâ”€â”€ auth.py            # Gestion de l'authentification.
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ Dockerfile             # Fichier pour construire l'image Docker.
â”œâ”€â”€ docker-compose.yml     # Configuration pour le dÃ©ploiement multi-conteneurs.
â”œâ”€â”€ docker-deploy.sh       # Script de dÃ©ploiement pour Linux/macOS.
â”œâ”€â”€ docker-deploy.ps1      # Script de dÃ©ploiement pour Windows PowerShell.
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python.
â””â”€â”€ README.md              # Ce fichier.
Use code with caution.
5. Technologies UtilisÃ©es
Backend : Flask
Recherche Vectorielle : FAISS (Facebook AI Similarity Search)
Embeddings : Sentence-Transformers (all-MiniLM-L6-v2)
GÃ©nÃ©ration de Langage : Azure OpenAI
Traitement de Documents : PyMuPDF (PDF), python-docx (Word), python-pptx (PowerPoint), Tesseract (OCR)
DÃ©ploiement : Docker, Docker Compose
6. PrÃ©requis
Python 3.10+
Docker et Docker Compose
Tesseract OCR :
Sous Windows : winget install --id=UB-Mannheim.TesseractOCR
Sous Linux (Debian/Ubuntu) : sudo apt-get install tesseract-ocr
Compte Azure OpenAI avec un point de terminaison et une clÃ© API.
7. Installation et Lancement
Ã‰tape 1 : Cloner le DÃ©pÃ´t et Configurer l'Environnement
Clonez ce dÃ©pÃ´t sur votre machine.

Copiez le fichier d'exemple d'environnement et remplissez-le avec vos valeurs:
- `cp .env.example .env` (Linux/macOS) ou `copy .env.example .env` (Windows)
- Le fichier `.env` est la SEULE source de vÃ©ritÃ© pour les secrets et configurations (ne rien coder en dur).

Configuration de la source de donnÃ©es via `DATA_SOURCE`:
- `DATA_SOURCE=local`: le script d'ingestion lit les fichiers locaux. Placez les documents sources dans `data/documents/` (des sous-dossiers sont acceptÃ©s). Aucune configuration Azure n'est requise.
- `DATA_SOURCE=azure`: le script d'ingestion lit les blobs Azure. Renseignez impÃ©rativement `AZURE_SAS_URL` (URL SAS du conteneur). Les variables Azure OpenAI (`AZURE_INFERENCE_SDK_ENDPOINT`, `AZURE_OPENAI_API_KEY`, `DEPLOYMENT_NAME`) doivent Ã©galement Ãªtre dÃ©finies pour la gÃ©nÃ©ration des rÃ©ponses.
Ã‰tape 2 : PrÃ©parer les DonnÃ©es
CrÃ©ez le dossier data/documents.
Placez tous les documents que le chatbot doit connaÃ®tre dans data/documents (il peut y avoir des sous-dossiers).
Ã‰tape 3 : Choisir une MÃ©thode de Lancement
MÃ©thode A : DÃ©ploiement avec Docker (RecommandÃ©)
Note importante : Le Dockerfile du projet pointe vers l'ancien script app.py. Vous devez le corriger manuellement avant de construire l'image.
Ouvrez le fichier Dockerfile et modifiez la derniÃ¨re ligne :
Remplacer : CMD ["python", "src/app.py"]
Par : CMD ["python", "src/app_unified.py"]
Construire la base de donnÃ©es vectorielle :
Pour que Docker puisse inclure la base de donnÃ©es dans l'image, vous devez la crÃ©er une premiÃ¨re fois localement.
Installez les dÃ©pendances : pip install -r requirements.txt
Lancez le script de crÃ©ation : python src/create_unified_vectordb.py
Construire et lancer les conteneurs Docker :
Sous Linux/macOS :
Generated bash
# Rendre le script exÃ©cutable
chmod +x docker-deploy.sh
# Construire l'image
./docker-deploy.sh build
# DÃ©marrer le conteneur
./docker-deploy.sh start
Use code with caution.
Bash
Sous Windows (dans PowerShell) :
Generated powershell
# Construire l'image
.\docker-deploy.ps1 build
# DÃ©marrer le conteneur
.\docker-deploy.ps1 start
Use code with caution.
Powershell
MÃ©thode B : Lancement Local
Installer les dÃ©pendances :
Generated bash
pip install -r requirements.txt
Use code with caution.
Bash
Construire la base de donnÃ©es vectorielle :
Generated bash
python src/create_unified_vectordb.py
Use code with caution.
Bash
Lancer l'application :
Generated bash
python src/app_unified.py
Use code with caution.
Bash
8. Utilisation
Une fois l'application lancÃ©e, accÃ©dez Ã  http://localhost:7860 dans votre navigateur.
Utilisez les identifiants par dÃ©faut pour vous connecter (crÃ©Ã©s au premier lancement) :
Identifiant : admin
Mot de passe : admin123
Utilisez la barre de recherche ou les questions suggÃ©rÃ©es pour interroger le chatbot. La page d'administration est accessible via le menu pour les utilisateurs avec le rÃ´le admin.
9. Maintenance
Pour mettre Ã  jour la base de connaissances du chatbot, ajoutez, modifiez ou supprimez des documents dans le dossier data/documents et relancez le script create_unified_vectordb.py.
Pour l'historique dÃ©taillÃ© des changements et des dÃ©cisions de conception, consultez le fichier suivi_projet.md.